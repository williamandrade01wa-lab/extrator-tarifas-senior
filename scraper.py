import requests
from bs4 import BeautifulSoup
import csv

def extrair():
    url = "https://app.beneficiofacil.com.br/apbprodutos.asp"
    print(f"üì° Acessando: {url}")
    
    try:
        response = requests.get(url, timeout=30)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.text, 'lxml')
        tabela = soup.find('table')
        
        if not tabela:
            print("‚ùå Erro: Tabela n√£o encontrada.")
            return

        linhas = tabela.find_all('tr')
        print(f"üìä Processando {len(linhas)} linhas para Importador Senior...")

        with open('tarifas_senior.csv', 'w', newline='', encoding='iso-8859-1') as f:
            # O importador do Senior costuma preferir ponto e v√≠rgula
            escritor = csv.writer(f, delimiter=';')
            
            # Come√ßamos de 1 para pular o cabe√ßalho do HTML, 
            # j√° que o Importador Autom√°tico geralmente l√™ dados puros.
            for linha in linhas[1:]:
                colunas = [col.text.strip() for col in linha.find_all('td')]
                
                if len(colunas) >= 4:
                    cod = colunas[0]
                    desc = colunas[1]
                    # colunas[2] √© o TIPO -> REMOVIDO
                    valor_raw = colunas[3]

                    # --- TRATAMENTO DO VALOR UNIT√ÅRIO ---
                    # Remove R$, espa√ßos e pontos de milhar. 
                    # Mant√©m a v√≠rgula para o campo "N√∫mero" do Senior entender as decimais.
                    valor_limpo = valor_raw.replace('R$', '').replace('.', '').replace(' ', '').strip()
                    
                    # Grava no CSV: COD;DESCRICAO;VALOR
                    escritor.writerow([cod, desc, valor_limpo])
            
            print(f"‚úÖ CSV pronto para o Processo Autom√°tico Senior!")

    except Exception as e:
        print(f"‚ùå Erro na extra√ß√£o: {e}")

if __name__ == "__main__":
    extrair()
